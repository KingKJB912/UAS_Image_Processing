{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python numpy tqdm albumentations pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73379dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Pongo\\anaconda3\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Pongo\\anaconda3\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c716c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup direktori selesai.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm # Progress bar untuk notebook\n",
    "from pathlib import Path\n",
    "\n",
    "# --- KONFIGURASI PATH (SESUAIKAN DISINI) ---\n",
    "# Folder dataset Virtual (Koryakinp)\n",
    "RAW_VIRTUAL_TRAIN = r\"D:\\Projek uas Image Processing\\Virtual_Chess\\train\" \n",
    "RAW_VIRTUAL_TEST  = r\"D:\\Projek uas Image Processing\\Virtual_Chess\\test\"\n",
    "\n",
    "# Folder dataset Synthetic (Thefamousrat)\n",
    "RAW_SYNTH_DATA = r\"D:\\Projek uas Image Processing\\Synthetic_Chess\\data\"\n",
    "\n",
    "# Folder Output Final\n",
    "OUTPUT_DIR = \"yolo_dataset\"\n",
    "\n",
    "# Mapping Kelas (Standar Universal)\n",
    "CLASS_MAP = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,  # Putih\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11 # Hitam\n",
    "}\n",
    "# Mapping nama di JSON Synthetic ke kode FEN\n",
    "SYNTH_NAME_MAP = {\n",
    "    \"white_pawn\": 'P', \"white_knight\": 'N', \"white_bishop\": 'B', \n",
    "    \"white_rook\": 'R', \"white_queen\": 'Q', \"white_king\": 'K',\n",
    "    \"black_pawn\": 'p', \"black_knight\": 'n', \"black_bishop\": 'b', \n",
    "    \"black_rook\": 'r', \"black_queen\": 'q', \"black_king\": 'k'\n",
    "}\n",
    "\n",
    "# Buat struktur folder output\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/images/{split}\", exist_ok=True)\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/labels/{split}\", exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup direktori selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2dd9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_bboxes_flat(fen, img_w=1280, img_h=1280):\n",
    "    \"\"\"\n",
    "    Untuk Dataset Virtual (Top-Down / Flat).\n",
    "    Mengubah string FEN menjadi list YOLO bboxes berdasarkan Grid 8x8.\n",
    "    \"\"\"\n",
    "    rows = fen.split('-') # Dataset ini pakai '-' sebagai pemisah, bukan '/'\n",
    "    if len(rows) != 8: return [] # Validasi error\n",
    "\n",
    "    bboxes = []\n",
    "    square_w = img_w / 8\n",
    "    square_h = img_h / 8\n",
    "    \n",
    "    for r, row_str in enumerate(rows): # r: 0-7\n",
    "        c = 0 \n",
    "        for char in row_str:\n",
    "            if char.isdigit():\n",
    "                c += int(char)\n",
    "            else:\n",
    "                if char in CLASS_MAP:\n",
    "                    class_id = CLASS_MAP[char]\n",
    "                    # Hitung center & size (Normalized 0-1)\n",
    "                    x_center = (c * square_w + square_w / 2) / img_w\n",
    "                    y_center = (r * square_h + square_h / 2) / img_h\n",
    "                    w = square_w / img_w\n",
    "                    h = square_h / img_h\n",
    "                    bboxes.append([class_id, x_center, y_center, w, h])\n",
    "                c += 1\n",
    "    return bboxes\n",
    "\n",
    "def calculate_homography_box(corners_norm, cell_x, cell_y, img_w, img_h):\n",
    "    \"\"\"\n",
    "    Untuk Dataset Synthetic (Perspektif).\n",
    "    Menghitung posisi kotak bidak berdasarkan 4 sudut papan menggunakan Homography.\n",
    "    \"\"\"\n",
    "    # 1. Definisi Sudut Papan Ideal (Koordinat Papan Catur 8x8)\n",
    "    # Urutan: Top-Left, Top-Right, Bottom-Right, Bottom-Left\n",
    "    src_pts = np.array([[0, 0], [8, 0], [8, 8], [0, 8]], dtype=np.float32)\n",
    "    \n",
    "    # 2. Sudut Papan di Gambar (dari JSON) -> Denormalisasi ke Pixel\n",
    "    dst_pts = np.array(corners_norm, dtype=np.float32)\n",
    "    dst_pts[:, 0] *= img_w\n",
    "    dst_pts[:, 1] *= img_h\n",
    "    \n",
    "    # 3. Hitung Matriks Homography\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "    \n",
    "    # 4. Tentukan koordinat sel target (misal E4 -> x=4, y=4)\n",
    "    # Kita ambil 4 titik sudut sel tersebut\n",
    "    cell_corners = np.array([\n",
    "        [cell_x, cell_y],         # TL\n",
    "        [cell_x + 1, cell_y],     # TR\n",
    "        [cell_x + 1, cell_y + 1], # BR\n",
    "        [cell_x, cell_y + 1]      # BL\n",
    "    ], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    \n",
    "    # 5. Proyeksikan (Transform) titik sel ke gambar perspektif\n",
    "    transformed_corners = cv2.perspectiveTransform(cell_corners, M)\n",
    "    \n",
    "    # 6. Buat Bounding Box yang melingkupi area yang terproyeksi\n",
    "    pts = transformed_corners.reshape(-1, 2)\n",
    "    x_min, y_min = np.min(pts, axis=0)\n",
    "    x_max, y_max = np.max(pts, axis=0)\n",
    "    \n",
    "    # Konversi ke YOLO format (normalized)\n",
    "    box_w = (x_max - x_min)\n",
    "    box_h = (y_max - y_min)\n",
    "    x_c = x_min + box_w / 2\n",
    "    y_c = y_min + box_h / 2\n",
    "    \n",
    "    return x_c/img_w, y_c/img_h, box_w/img_w, box_h/img_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0711052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_bboxes_flat(fen, img_w=1280, img_h=1280):\n",
    "    \"\"\"\n",
    "    Untuk Dataset Virtual (Top-Down / Flat).\n",
    "    Mengubah string FEN menjadi list YOLO bboxes berdasarkan Grid 8x8.\n",
    "    \"\"\"\n",
    "    rows = fen.split('-') # Dataset ini pakai '-' sebagai pemisah, bukan '/'\n",
    "    if len(rows) != 8: return [] # Validasi error\n",
    "\n",
    "    bboxes = []\n",
    "    square_w = img_w / 8\n",
    "    square_h = img_h / 8\n",
    "    \n",
    "    for r, row_str in enumerate(rows): # r: 0-7\n",
    "        c = 0 \n",
    "        for char in row_str:\n",
    "            if char.isdigit():\n",
    "                c += int(char)\n",
    "            else:\n",
    "                if char in CLASS_MAP:\n",
    "                    class_id = CLASS_MAP[char]\n",
    "                    # Hitung center & size (Normalized 0-1)\n",
    "                    x_center = (c * square_w + square_w / 2) / img_w\n",
    "                    y_center = (r * square_h + square_h / 2) / img_h\n",
    "                    w = square_w / img_w\n",
    "                    h = square_h / img_h\n",
    "                    bboxes.append([class_id, x_center, y_center, w, h])\n",
    "                c += 1\n",
    "    return bboxes\n",
    "\n",
    "def calculate_homography_box(corners_norm, cell_x, cell_y, img_w, img_h):\n",
    "    \"\"\"\n",
    "    Untuk Dataset Synthetic (Perspektif).\n",
    "    Menghitung posisi kotak bidak berdasarkan 4 sudut papan menggunakan Homography.\n",
    "    \"\"\"\n",
    "    # 1. Definisi Sudut Papan Ideal (Koordinat Papan Catur 8x8)\n",
    "    # Urutan: Top-Left, Top-Right, Bottom-Right, Bottom-Left\n",
    "    src_pts = np.array([[0, 0], [8, 0], [8, 8], [0, 8]], dtype=np.float32)\n",
    "    \n",
    "    # 2. Sudut Papan di Gambar (dari JSON) -> Denormalisasi ke Pixel\n",
    "    dst_pts = np.array(corners_norm, dtype=np.float32)\n",
    "    dst_pts[:, 0] *= img_w\n",
    "    dst_pts[:, 1] *= img_h\n",
    "    \n",
    "    # 3. Hitung Matriks Homography\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "    \n",
    "    # 4. Tentukan koordinat sel target (misal E4 -> x=4, y=4)\n",
    "    # Kita ambil 4 titik sudut sel tersebut\n",
    "    cell_corners = np.array([\n",
    "        [cell_x, cell_y],         # TL\n",
    "        [cell_x + 1, cell_y],     # TR\n",
    "        [cell_x + 1, cell_y + 1], # BR\n",
    "        [cell_x, cell_y + 1]      # BL\n",
    "    ], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    \n",
    "    # 5. Proyeksikan (Transform) titik sel ke gambar perspektif\n",
    "    transformed_corners = cv2.perspectiveTransform(cell_corners, M)\n",
    "    \n",
    "    # 6. Buat Bounding Box yang melingkupi area yang terproyeksi\n",
    "    pts = transformed_corners.reshape(-1, 2)\n",
    "    x_min, y_min = np.min(pts, axis=0)\n",
    "    x_max, y_max = np.max(pts, axis=0)\n",
    "    \n",
    "    # Konversi ke YOLO format (normalized)\n",
    "    box_w = (x_max - x_min)\n",
    "    box_h = (y_max - y_min)\n",
    "    x_c = x_min + box_w / 2\n",
    "    y_c = y_min + box_h / 2\n",
    "    \n",
    "    return x_c/img_w, y_c/img_h, box_w/img_w, box_h/img_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43243142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing Virtual Dataset: train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd0615711fc4d508e2e3ddb20cdc676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing Virtual Dataset: val...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56838782079c461e9929b0d728e84417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_virtual_folder(source_folder, split_name):\n",
    "    print(f\"ðŸ”„ Processing Virtual Dataset: {split_name}...\")\n",
    "    \n",
    "    # Ambil semua gambar jpeg\n",
    "    images = glob.glob(os.path.join(source_folder, \"*.jpeg\")) + glob.glob(os.path.join(source_folder, \"*.jpg\"))\n",
    "    \n",
    "    for img_path in tqdm(images):\n",
    "        filename = os.path.basename(img_path)\n",
    "        \n",
    "        # 1. Parsing FEN dari nama file\n",
    "        # Contoh: rnbqkbnr-pppppppp-8-8-8-8-PPPPPPPP-RNBQKBNR.jpeg\n",
    "        fen_clean = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # 2. Load Gambar untuk cek ukuran (biasanya fixed, tapi aman dicek)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # 3. Generate Labels\n",
    "        bboxes = fen_to_bboxes_flat(fen_clean, w, h)\n",
    "        \n",
    "        # 4. Simpan (Copy gambar & Write .txt)\n",
    "        # Kita beri prefix 'virt_' biar tidak bentrok nama\n",
    "        new_filename = f\"virt_{filename}\"\n",
    "        shutil.copy(img_path, f\"{OUTPUT_DIR}/images/{split_name}/{new_filename}\")\n",
    "        \n",
    "        txt_name = os.path.splitext(new_filename)[0] + \".txt\"\n",
    "        with open(f\"{OUTPUT_DIR}/labels/{split_name}/{txt_name}\", 'w') as f:\n",
    "            for b in bboxes:\n",
    "                f.write(f\"{b[0]} {b[1]:.6f} {b[2]:.6f} {b[3]:.6f} {b[4]:.6f}\\n\")\n",
    "\n",
    "# Eksekusi\n",
    "process_virtual_folder(RAW_VIRTUAL_TRAIN, 'train') # Masuk ke folder train\n",
    "process_virtual_folder(RAW_VIRTUAL_TEST, 'val')    # Masuk ke folder val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5413bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing Synthetic Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fd1eda67504ccb8e1484742462d73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_synthetic_data(source_folder, split_ratio=0.9):\n",
    "    print(\"ðŸ”„ Processing Synthetic Dataset...\")\n",
    "    \n",
    "    # Cari pasangan JSON dan JPG\n",
    "    json_files = glob.glob(os.path.join(source_folder, \"*.json\"))\n",
    "    \n",
    "    # Mapping Huruf Kolom ke Index (A=0, B=1, dst)\n",
    "    col_map = {chr(65+i): i for i in range(8)} # {'A':0, 'B':1, ...}\n",
    "    \n",
    "    count_train = 0\n",
    "    \n",
    "    for json_path in tqdm(json_files):\n",
    "        # Cari gambar pasangannya\n",
    "        base_name = os.path.splitext(os.path.basename(json_path))[0]\n",
    "        img_path = os.path.join(source_folder, base_name + \".jpeg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(source_folder, base_name + \".jpg\")\n",
    "            if not os.path.exists(img_path): continue\n",
    "        \n",
    "        # Load JSON & Image\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # Data Extraction\n",
    "        corners = data.get('corners') # [[x,y], [x,y], ...] normalized\n",
    "        config = data.get('config')   # {\"A1\": \"white_rook\", ...}\n",
    "        \n",
    "        if not corners or not config: continue\n",
    "        \n",
    "        yolo_labels = []\n",
    "        \n",
    "        # Loop setiap bidak di config\n",
    "        for cell_name, piece_name in config.items():\n",
    "            # Parse cell name (e.g., \"E4\")\n",
    "            col_char = cell_name[0] # \"E\"\n",
    "            row_char = cell_name[1] # \"4\"\n",
    "            \n",
    "            # Konversi ke koordinat grid (0-7)\n",
    "            # A1 di deskripsi dataset = [0,0]. Biasanya A=0 (x), 1=0 (y).\n",
    "            grid_x = col_map[col_char] \n",
    "            grid_y = int(row_char) - 1 \n",
    "            \n",
    "            # Map nama bidak ke ID\n",
    "            if piece_name not in SYNTH_NAME_MAP: continue\n",
    "            fen_char = SYNTH_NAME_MAP[piece_name]\n",
    "            class_id = CLASS_MAP[fen_char]\n",
    "            \n",
    "            # HITUNG GEOMETRI (Homography)\n",
    "            # Input: corners dataset, posisi grid x,y\n",
    "            xc, yc, bw, bh = calculate_homography_box(corners, grid_x, grid_y, w, h)\n",
    "            \n",
    "            # Validasi agar tidak keluar gambar\n",
    "            xc = max(0, min(1, xc))\n",
    "            yc = max(0, min(1, yc))\n",
    "            bw = max(0, min(1, bw))\n",
    "            bh = max(0, min(1, bh))\n",
    "            \n",
    "            yolo_labels.append(f\"{class_id} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "            \n",
    "        # Simpan Data (Random Split)\n",
    "        split = 'train' if np.random.rand() < split_ratio else 'val'\n",
    "        \n",
    "        new_filename = f\"synth_{base_name}.jpg\"\n",
    "        cv2.imwrite(f\"{OUTPUT_DIR}/images/{split}/{new_filename}\", img)\n",
    "        \n",
    "        txt_name = f\"synth_{base_name}.txt\"\n",
    "        with open(f\"{OUTPUT_DIR}/labels/{split}/{txt_name}\", 'w') as f:\n",
    "            f.write('\\n'.join(yolo_labels))\n",
    "\n",
    "# Eksekusi\n",
    "process_synthetic_data(RAW_SYNTH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "# 1. Load Model Pre-trained (Masih \"bodoh\" soal catur)\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "print(\"ðŸš€ Memulai validasi sebelum training (Baseline)...\")\n",
    "print(\"âš ï¸ Harap maklum jika hasilnya 0% atau error, karena model belum kenal kelas catur.\")\n",
    "\n",
    "# 2. Jalankan Validasi\n",
    "# fraction=0.1 artinya kita cuma pakai 10% data validasi biar cepat\n",
    "# plots=True wajib agar YOLO men-generate gambar confusion matrix\n",
    "results = model.val(data=f\"{OUTPUT_DIR}/dataset.yaml\", imgsz=640, fraction=0.1, plots=True)\n",
    "\n",
    "print(\"âœ… Validasi selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59da61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cari folder hasil validasi terakhir\n",
    "# Biasanya ada di runs/detect/val, val2, val3...\n",
    "val_folders = sorted(glob.glob('runs/detect/val*'), key=os.path.getmtime)\n",
    "\n",
    "if val_folders:\n",
    "    latest_run = val_folders[-1]\n",
    "    cm_path = os.path.join(latest_run, 'confusion_matrix.png')\n",
    "    \n",
    "    if os.path.exists(cm_path):\n",
    "        print(f\"ðŸ“Š Menampilkan Confusion Matrix dari: {cm_path}\")\n",
    "        display(Image(filename=cm_path, width=800))\n",
    "    else:\n",
    "        print(\"âš ï¸ Gambar confusion_matrix.png tidak ditemukan. Mungkin model tidak mendeteksi apapun (semua background).\")\n",
    "        # Coba tampilkan confusion matrix ternormalisasi jika ada\n",
    "        cm_norm_path = os.path.join(latest_run, 'confusion_matrix_normalized.png')\n",
    "        if os.path.exists(cm_norm_path):\n",
    "            display(Image(filename=cm_norm_path, width=800))\n",
    "else:\n",
    "    print(\"âŒ Belum ada folder runs/detect/ ditemukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3543e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required objects exist and select proper device (CPU if no CUDA)\n",
    "import torch\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except Exception:\n",
    "    # If ultralytics is not installed, user must install it in the environment.\n",
    "    raise\n",
    "\n",
    "# Ensure yaml_path exists (fallback to expected default)\n",
    "yaml_path = globals().get('yaml_path', 'yolo_dataset/dataset.yaml')\n",
    "\n",
    "# Ensure model exists; if not, load a small pretrained model\n",
    "if 'model' not in globals() or model is None:\n",
    "    model = YOLO('yolov8n.pt')  # download/load a small YOLOv8 model\n",
    "\n",
    "# Pick device safely: use CPU when no CUDA devices are available\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "    device = '0'  # first GPU (string form)\n",
    "    print(f\"Using CUDA device(s): {device}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,        # Sesuaikan dengan VRAM. Coba 16, 32, atau 64. Semakin besar semakin cepat (selama gak Out of Memory).\n",
    "    workers=4,       # Jumlah core CPU untuk load data. (Di Windows, set 0 jika error, tapi 4 lebih cepat)\n",
    "    cache=True,      # Cache gambar ke RAM (Sangat mempercepat jika RAM > 16GB)\n",
    "    device=device,   # Use selected device\n",
    "    patience=5       # Stop training jika akurasi tidak naik selama 5 epoch (Early Stopping)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
